{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Regression\n",
    ">Predicting a continuous real value output.\n",
    "\n",
    "> Some notation here:\n",
    ">> m: training set size\n",
    ">> x: input variable or features (vector in this case)\n",
    ">> y: output variable or target variable (vector in this case)\n",
    "\n",
    ">> To denote the _ith_ training example or traini: $(x_{i}, y_{i})$\n",
    "\n",
    "\n",
    "> In simple terms linear regression is about finding what is the mathematical relationship between the input and the output.\n",
    "> And for one variable regression, the model need to define a line that best describe this relationship $m * x + b$ this function is called _hypothesis_  noted $h(\\theta) = \\theta_{0} + \\theta_{1} * x$\n",
    "> \n",
    "> How do we know how well a line describes the relationship(data)? By computing a loss/cost function. The idea is to find the line with the least loss.\n",
    "> \n",
    "> A common cost function we can use is the mean squared error function defined by:\n",
    ">> $Cost(J(\\theta)) = \\frac{1}{2m} * \\sum \\limits _{i = 1} ^ {m} [(\\theta_{0} + \\theta_{1} * x_{i}) - y_{i}] ^ 2$\n",
    "> \n",
    "> The idea is to minimize $J(\\theta)$ in respect to $\\theta_{0}$ and $\\theta_{1}$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6a4c06aacf2f08d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
