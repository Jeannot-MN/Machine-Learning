{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download the NLTK tokenizer models\n",
    "nltk.download('punkt')\n",
    "\n",
    "books = ['HP1', 'HP2', 'HP3', 'HP4', 'HP5', 'HP6', 'HP7']\n",
    "tokens = []\n",
    "\n",
    "for book in books:\n",
    "    try:\n",
    "        with open(f'assets/harry_potter/{book}.txt', encoding='utf8') as file:\n",
    "            file_content = file.read()\n",
    "            file_content = re.sub(r'[^\\w\\s]', '', file_content).lower()\n",
    "            pages = file_content.split('\\n')\n",
    "            \n",
    "            book_tokens = []\n",
    "            for page_content in pages:\n",
    "                page_tokens = word_tokenize(page_content)\n",
    "                book_tokens.append(page_tokens)\n",
    "            tokens.append(book_tokens)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {book}.txt not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {book}.txt: {e}\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for index, book in enumerate(tokens):\n",
    "    for page in book:\n",
    "        page_tri_grams = [' '.join(ngram) for ngram in ngrams(page, 3)]\n",
    "        data.append(page_tri_grams)\n",
    "        labels.append(books[index])\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.15, random_state=42)\n",
    "train_data, validation_data, train_labels, validation_labels = train_test_split(train_data, train_labels, test_size=0.15, random_state=42)\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.word_probs = {}\n",
    "        self.class_probs = {}\n",
    "        self.tri_gram_probs = {}\n",
    "        self.classes = set()\n",
    "\n",
    "    def train(self, train_data, labels):\n",
    "        word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        tri_grams_count = defaultdict(lambda: defaultdict(int))\n",
    "        class_counts = defaultdict(int)\n",
    "\n",
    "        # Count words and classes\n",
    "        for i, text in enumerate(train_data):\n",
    "            label = labels[i]\n",
    "            self.classes.add(label)\n",
    "            class_counts[label] += 1\n",
    "\n",
    "            for trigram in text:\n",
    "                tri_grams_count[label][trigram] += 1\n",
    "                \n",
    "                for word in trigram.split(' '):\n",
    "                    word_counts[label][word] += 1\n",
    "\n",
    "        # Calculate class probabilities\n",
    "        self.class_probs = {c: count / len(labels) for c, count in class_counts.items()}\n",
    "        \n",
    "        # Calculate 3-gram probabilities for each class\n",
    "        for label in self.classes:\n",
    "            total_count = sum(tri_grams_count[label].values())\n",
    "            self.tri_gram_probs[label] = {\n",
    "                tg: (count + 1) / (total_count + len(tri_grams_count[label]))\n",
    "                for tg, count in tri_grams_count[label].items()\n",
    "            }\n",
    "        \n",
    "        # Calculate word probabilities for each class\n",
    "        for label in self.classes:\n",
    "            total_count = sum(word_counts[label].values())\n",
    "            self.word_probs[label] = {\n",
    "                word: (count + 1) / (total_count + len(word_counts[label]))\n",
    "                for word, count in word_counts[label].items()\n",
    "            }\n",
    "\n",
    "    def predict(self, text):\n",
    "        results = {}\n",
    "        for label in self.classes:\n",
    "            prob = self.class_probs[label]\n",
    "    \n",
    "            for trigram in text:\n",
    "                if trigram in self.tri_gram_probs[label]:\n",
    "                    prob *= self.tri_gram_probs[label][trigram]\n",
    "                else:\n",
    "                    prob *= 1 / (sum(self.tri_gram_probs[label].values()) + len(self.tri_gram_probs[label]))\n",
    "                    \n",
    "                for word in trigram.split(' '):\n",
    "                    if word in self.word_probs[label]:\n",
    "                        prob *= self.word_probs[label][word]\n",
    "                    else:\n",
    "                        prob *= 1 / (sum(self.word_probs[label].values()) + len(self.word_probs[label]))\n",
    "    \n",
    "            results[label] = prob\n",
    "    \n",
    "        return max(results, key=results.get)\n",
    "\n",
    "# Initialize and train the classifier\n",
    "classifier = NaiveBayesClassifier()\n",
    "classifier.train(train_data, train_labels)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "correct = 0\n",
    "for i, text in enumerate(test_data):\n",
    "    prediction = classifier.predict(text)\n",
    "    if prediction == test_labels[i]:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(test_data)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c49fc2adc3d7489"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
